{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f416dd-9f7d-4d5c-98f8-60d9c86c7c82",
   "metadata": {},
   "source": [
    "### Churn @ Robinhood\n",
    "#### Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db448b89-e3eb-4152-b27d-88017574821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: <Managed Device 0>\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "try:\n",
    "    print(\"Available GPUs:\", cuda.gpus)\n",
    "except cuda.CudaSupportError as e:\n",
    "    print(\"CUDA Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6188b919-7526-4909-ab1e-62af0eac877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf as cf\n",
    "equity_df_raw = cf.read_csv('./data/equity_value_data.csv')\n",
    "features_df_raw = cf.read_csv('./data/features_data.csv')\n",
    "\n",
    "equity_df = equity_df_raw.copy()\n",
    "features_df = features_df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b5d0bf5-595b-4bd2-8492-a42f0005f0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'>\n",
      "RangeIndex: 1119158 entries, 0 to 1119157\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count    Dtype\n",
      "---  ------        --------------    -----\n",
      " 0   timestamp     1119158 non-null  object\n",
      " 1   close_equity  1119158 non-null  float64\n",
      " 2   user_id       1119158 non-null  object\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 72.6+ MB\n"
     ]
    }
   ],
   "source": [
    "equity_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b93a2e-9529-4e93-a6de-50a747649a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'>\n",
      "RangeIndex: 5584 entries, 0 to 5583\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count  Dtype\n",
      "---  ------                        --------------  -----\n",
      " 0   risk_tolerance                5584 non-null   object\n",
      " 1   investment_experience         5584 non-null   object\n",
      " 2   liquidity_needs               5584 non-null   object\n",
      " 3   platform                      5584 non-null   object\n",
      " 4   time_spent                    5584 non-null   float64\n",
      " 5   instrument_type_first_traded  5584 non-null   object\n",
      " 6   first_deposit_amount          5584 non-null   float64\n",
      " 7   time_horizon                  5584 non-null   object\n",
      " 8   user_id                       5584 non-null   object\n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 896.8+ KB\n"
     ]
    }
   ],
   "source": [
    "features_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0433abdc-8453-42e0-ab0f-1ec3b1c802a6",
   "metadata": {},
   "source": [
    "#### a). What percentage of users have churned in the data?\n",
    "A user is *churned* when their equity falls below 10 usd for 28 consecutive calendar days or longer having perviously been at least 10 usd\n",
    "\n",
    "**NOTE** Since no equities falls under 10 usd, threshold is set to a variable usd instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09e65c4e-4ebf-49bd-b051-4f709ed91887",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churned Percentage: 1.58%\n",
      "\n",
      "Churned Users: 0     0503b35d3715f13fec0a6b7319a32a4f\n",
      "1     030f4ca7bb7bf14fe5a442b9bffc19e8\n",
      "2     08c81465c35d7b5208f4c14bd5bcc3bb\n",
      "3     0c29d08eaf4a53f9c33218de00371311\n",
      "4     0ee1c5d34c5d6bc0af382cc51eabea5c\n",
      "                    ...               \n",
      "83    f0b60bf9e2ceba027dc1f67d0152f4fa\n",
      "84    f1c5f7bb83a2e6b0afe7d718cde09e1d\n",
      "85    f55741ace6b614e9017a6b6e19367a7f\n",
      "86    f9e3f4295ec8017a75ffed3184bc9ce6\n",
      "87    fc3e52dfa44438cd91838b1f48b7e57a\n",
      "Name: user_id, Length: 88, dtype: object\n",
      "\n",
      "Total Users: 5584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set threshold\n",
    "thresh = 12\n",
    "\n",
    "# Step 1: Ensure the timestamp column is datetime and sort the data\n",
    "equity_df['timestamp'] = cf.to_datetime(equity_df['timestamp'])\n",
    "equity_df = equity_df.sort_values(['user_id', 'timestamp'])\n",
    "\n",
    "# Step 2: Flag close_equity below threshold\n",
    "equity_df[f'below_{thresh}'] = (equity_df['close_equity'] < thresh).astype(int)\n",
    "\n",
    "# Step 3: Compute rolling 28-day windows for each user\n",
    "equity_df[f'below_{thresh}_28d'] = equity_df.groupby('user_id')[f'below_{thresh}'].rolling(window=28, min_periods=28).sum().reset_index(0, drop=True)\n",
    "\n",
    "# Step 4: Identify churn (continuous 28 days below $11)\n",
    "equity_df['churn'] = (equity_df[f'below_{thresh}_28d'] == 28).astype(int).copy()\n",
    "\n",
    "# Step 5: Check if the user ever had close_equity >= 11\n",
    "# Group by 'user_id' to find the max close_equity\n",
    "user_max_equity = equity_df.groupby('user_id')['close_equity'].max().reset_index()\n",
    "user_max_equity.rename(columns={\"close_equity\": \"max_equity\"}, inplace=True)\n",
    "\n",
    "# Merge back to associate max_equity with each user_id in the main DataFrame\n",
    "equity_df = equity_df.merge(user_max_equity, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# Add a flag for users who had close_equity >= 11 at some point\n",
    "equity_df[f'above_{thresh}_before'] = (equity_df['max_equity'] >= thresh).astype(int)\n",
    "\n",
    "# Step 6: Filter churned users\n",
    "churned_users = equity_df.loc[\n",
    "    (equity_df['churn'] == 1) & (equity_df[f'above_{thresh}_before'] == 1),\n",
    "    'user_id'\n",
    "].unique()\n",
    "\n",
    "# Step 7: Calculate the churn percentage\n",
    "total_users = equity_df['user_id'].nunique()\n",
    "churn_percentage = (len(churned_users) / total_users) * 100\n",
    "\n",
    "print(f\"Churned Percentage: {churn_percentage:.2f}%\\n\")\n",
    "print(f\"Churned Users: {churned_users}\\n\")\n",
    "print(f\"Total Users: {total_users}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3b396b-384c-4d87-b082-433b1ae29592",
   "metadata": {},
   "source": [
    "Find total days on platform for each user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af13b59-5dd3-45b4-b528-b6631b8dd921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'>\n",
      "RangeIndex: 1119158 entries, 0 to 1119157\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count    Dtype\n",
      "---  ------           --------------    -----\n",
      " 0   timestamp        1119158 non-null  datetime64[ns]\n",
      " 1   close_equity     1119158 non-null  float64\n",
      " 2   user_id          1119158 non-null  object\n",
      " 3   below_12         1119158 non-null  int64\n",
      " 4   below_12_28d     971628 non-null   int64\n",
      " 5   churn            971628 non-null   int64\n",
      " 6   max_equity       1119158 non-null  float64\n",
      " 7   above_12_before  1119158 non-null  int64\n",
      "dtypes: datetime64[ns](1), float64(2), int64(4), object(1)\n",
      "memory usage: 98.5+ MB\n"
     ]
    }
   ],
   "source": [
    "equity_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b603a63a-7516-40a8-890a-60051b856f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               user_id  total_days_on_platform\n",
      "0     0012db34aa7b083f5714e7831195e54d                     365\n",
      "1     001d6c77dbdb3213cead7673f250bfdc                     365\n",
      "2     002e4653171ddc61c3cd30603cd7bd3e                     184\n",
      "3     00384fa9be6fdca1b786bae70d78f88f                     177\n",
      "4     0042aac295a0d4df88f4b83012778bd4                     365\n",
      "...                                ...                     ...\n",
      "5579  ff9ee08791e20724a86995ab2bc72578                     365\n",
      "5580  ffa12d2f97e310910291f9b26fb2318d                     365\n",
      "5581  ffae713096867a32e74f633060667153                     324\n",
      "5582  ffbda9a14e07718e2b21fb03896d21c5                     185\n",
      "5583  ffc1e622f3a0b2666f09a6dcb7f27918                     299\n",
      "\n",
      "[5584 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert cudf DataFrame to pandas for grouping, if necessary\n",
    "equity_df = equity_df.to_pandas()\n",
    "\n",
    "# Group by `user_id` and calculate the total days on platform\n",
    "total_days = equity_df.groupby('user_id')['timestamp'].agg(lambda x: (x.max() - x.min()).days + 1).reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "total_days.columns = ['user_id', 'total_days_on_platform']\n",
    "\n",
    "# Display the result\n",
    "print(total_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d55fca-a987-4a77-b890-877903a4334e",
   "metadata": {},
   "source": [
    "b). Build a classifier given a user with their features assigns a churn probability for every user and predicts which users will churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd97237-dcab-4c73-95aa-a5c413508701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churned\n",
       "0    5496\n",
       "1      88\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the 'churned' column\n",
    "features_df['churned'] = features_df['user_id'].isin(churned_users).astype('int32')\n",
    "features_df['churned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a1add47-ea97-4dad-8e70-4874e4a54f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'>\n",
      "RangeIndex: 5584 entries, 0 to 5583\n",
      "Data columns (total 10 columns):\n",
      " #   Column                        Non-Null Count  Dtype\n",
      "---  ------                        --------------  -----\n",
      " 0   risk_tolerance                5584 non-null   object\n",
      " 1   investment_experience         5584 non-null   object\n",
      " 2   liquidity_needs               5584 non-null   object\n",
      " 3   platform                      5584 non-null   object\n",
      " 4   time_spent                    5584 non-null   float64\n",
      " 5   instrument_type_first_traded  5584 non-null   object\n",
      " 6   first_deposit_amount          5584 non-null   float64\n",
      " 7   time_horizon                  5584 non-null   object\n",
      " 8   user_id                       5584 non-null   object\n",
      " 9   churned                       5584 non-null   int32\n",
      "dtypes: float64(2), int32(1), object(7)\n",
      "memory usage: 918.7+ KB\n"
     ]
    }
   ],
   "source": [
    "features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbcdadf8-f7ae-41b7-9518-4dd0397c29d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>time_spent</th>\n",
       "      <td>5584.0</td>\n",
       "      <td>34.509706</td>\n",
       "      <td>155.080551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.848908</td>\n",
       "      <td>13.474708</td>\n",
       "      <td>33.823829</td>\n",
       "      <td>8788.32945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_deposit_amount</th>\n",
       "      <td>5584.0</td>\n",
       "      <td>633.566805</td>\n",
       "      <td>2118.323263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churned</th>\n",
       "      <td>5584.0</td>\n",
       "      <td>0.015759</td>\n",
       "      <td>0.124554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count        mean          std  min        25%  \\\n",
       "time_spent            5584.0   34.509706   155.080551  0.0   2.848908   \n",
       "first_deposit_amount  5584.0  633.566805  2118.323263  0.0  50.000000   \n",
       "churned               5584.0    0.015759     0.124554  0.0   0.000000   \n",
       "\n",
       "                             50%         75%          max  \n",
       "time_spent             13.474708   33.823829   8788.32945  \n",
       "first_deposit_amount  100.000000  500.000000  50000.00000  \n",
       "churned                 0.000000    0.000000      1.00000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7f11ab2-bca4-4881-ad94-35af73d48195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "risk_tolerance\n",
       "high_risk_tolerance    3566\n",
       "med_risk_tolerance     1779\n",
       "low_risk_tolerance      239\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df['risk_tolerance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31903243-60b0-4275-a747-06d9e8aeb812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "investment_experience\n",
       "limited_investment_exp      2578\n",
       "no_investment_exp           1796\n",
       "good_investment_exp         1134\n",
       "extensive_investment_exp      76\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df['investment_experience'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9beb3870-2b27-42ea-a5db-80308d321b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "investment_experience\n",
       "limited_investment_exp    2578\n",
       "no_investment_exp         1796\n",
       "good_investment_exp       1210\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change features of investment experience to 3\n",
    "features_df['investment_experience'] = features_df['investment_experience'].replace({\n",
    "    'extensive_investment_exp': 'good_investment_exp'\n",
    "})\n",
    "features_df['investment_experience'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d78a6b1c-2eec-436f-869c-66003cb49f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "liquidity_needs\n",
       "very_important_liq_need        4217\n",
       "somewhat_important_liq_need    1109\n",
       "not_important_liq_need          258\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df['liquidity_needs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe150636-a945-4013-b841-695e64088581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "platform\n",
       "iOS        3550\n",
       "Android    1529\n",
       "both        505\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df['platform'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a3dd258-9aee-40b0-b6f9-a4ebacf81382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instrument_type_first_traded\n",
       "stock       4827\n",
       "etp          383\n",
       "adr          197\n",
       "mlp           55\n",
       "reit          55\n",
       "cef           20\n",
       "wrt           16\n",
       "0             13\n",
       "rlt            9\n",
       "lp             8\n",
       "tracking       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df['instrument_type_first_traded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0157c5c1-783c-409f-8b63-712af461639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrument_type_first_traded\n",
      "stock        4827\n",
      "non_stock     757\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use vectorized operations to assign 'non_stock' to all values not equal to 'stock'\n",
    "features_df['instrument_type_first_traded'] = (\n",
    "    features_df['instrument_type_first_traded']\n",
    "    .where(features_df['instrument_type_first_traded'] == 'stock', 'non_stock')\n",
    ")\n",
    "\n",
    "# Check the updated value counts\n",
    "print(features_df['instrument_type_first_traded'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b05cbd52-fbe7-4b51-b903-1c1da7e43523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_horizon\n",
       "short_time_horizon    2833\n",
       "long_time_horizon     1833\n",
       "med_time_horizon       918\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df['time_horizon'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42c65ada-9125-42dd-a23e-4d2e60cb5125",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 144 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n144 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'total_days'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/utils/_indexing.py\", line 364, in _get_column_indices\n    col_idx = all_columns.get_loc(col)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 'total_days'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 652, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 586, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 992, in fit_transform\n    self._validate_column_callables(X)\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 551, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/utils/_indexing.py\", line 372, in _get_column_indices\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\nValueError: A given column is not a column of the dataframe\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 78\u001b[0m\n\u001b[1;32m     66\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     67\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[1;32m     68\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, model)\n\u001b[1;32m     69\u001b[0m ])\n\u001b[1;32m     71\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     72\u001b[0m     pipeline,\n\u001b[1;32m     73\u001b[0m     param_grid,\n\u001b[1;32m     74\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Adjust scoring based on your metric of interest\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 78\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchurned\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m best_pipeline \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Predict using the best pipeline\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1023\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1018\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1023\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1570\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1570\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1000\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    995\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    997\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    998\u001b[0m     )\n\u001b[0;32m-> 1000\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    516\u001b[0m     )\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 144 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n144 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'total_days'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/utils/_indexing.py\", line 364, in _get_column_indices\n    col_idx = all_columns.get_loc(col)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 'total_days'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 652, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 586, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 992, in fit_transform\n    self._validate_column_callables(X)\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 551, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/oem/Documents/github/magnimind_projects/magpenv/lib/python3.12/site-packages/sklearn/utils/_indexing.py\", line 372, in _get_column_indices\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\nValueError: A given column is not a column of the dataframe\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "features_df = features_df.to_pandas()\n",
    "\n",
    "# Merge total_days into features_df on 'user_id'\n",
    "features_df = features_df.merge(total_days, on='user_id', how='left')\n",
    "\n",
    "# Drop `user_id` and `churned` columns for training\n",
    "features_df = features_df.drop(columns=['user_id'])\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = ['risk_tolerance', 'investment_experience', 'liquidity_needs', 'platform', \n",
    "                        'instrument_type_first_traded', 'time_horizon']\n",
    "numerical_features = ['time_spent', 'first_deposit_amount', 'total_days']\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(sparse_output=False, handle_unknown='ignore', min_frequency=0.01)\n",
    "\n",
    "# Combine preprocessors in a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define anomaly detection models and parameter grids\n",
    "param_grids = {\n",
    "    'IsolationForest': {\n",
    "        'model__contamination': [0.005, 0.01, 0.02, 0.05],\n",
    "        'model__max_samples': [128, 256, 'auto'],\n",
    "        'model__max_features': [0.25, 0.5, 0.75, 1.0]\n",
    "    },\n",
    "    'LocalOutlierFactor': {\n",
    "        'model__n_neighbors': [10, 20, 35, 50],\n",
    "        'model__leaf_size': [10, 25, 30, 50],\n",
    "        'model__contamination': [0.005, 0.01, 0.02, 0.05]\n",
    "    },\n",
    "    'OneClassSVM': {\n",
    "        'model__nu': [0.005, 0.01, 0.05, 0.1],\n",
    "        'model__gamma': ['scale', 'auto'],\n",
    "        'model__kernel': ['rbf', 'poly', 'linear']\n",
    "    }\n",
    "}\n",
    "\n",
    "true_labels = features_df['churned']  # Ground truth labels for evaluation\n",
    "\n",
    "for name, param_grid in param_grids.items():\n",
    "    if name == 'IsolationForest':\n",
    "        model = IsolationForest(random_state=42)\n",
    "    elif name == 'LocalOutlierFactor':\n",
    "        model = LocalOutlierFactor(novelty=True)\n",
    "    elif name == 'OneClassSVM':\n",
    "        model = OneClassSVM()\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        scoring='f1_macro',  # Adjust scoring based on your metric of interest\n",
    "        cv=3\n",
    "    )\n",
    "\n",
    "    grid_search.fit(features_df.drop(columns=['churned']), true_labels)\n",
    "    best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "    # Predict using the best pipeline\n",
    "    predictions = best_pipeline.predict(features_df.drop(columns=['churned']))\n",
    "    binary_predictions = (predictions == 1).astype(int)\n",
    "\n",
    "    # Print classification report\n",
    "    print(f\"\\n{name} Best Parameters: {grid_search.best_params_}\\n\")\n",
    "    print(f\"{name} Classification Report:\\n\")\n",
    "    print(classification_report(true_labels, binary_predictions))\n",
    "\n",
    "    # Print feature importances if available\n",
    "    if hasattr(best_pipeline.named_steps['model'], 'feature_importances_'):\n",
    "        feature_importances = best_pipeline.named_steps['model'].feature_importances_\n",
    "        feature_names = numerical_features + list(best_pipeline.named_steps['preprocessor']\n",
    "                                                  .transformers_[1][1]\n",
    "                                                  .get_feature_names_out(categorical_features))\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': feature_importances\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "        print(f\"\\n{name} Feature Importances:\\n\")\n",
    "        print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e0ffab-936d-4c0e-8e81-4123296cca5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (magpenv)",
   "language": "python",
   "name": "magpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
